{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0169dd69",
   "metadata": {},
   "source": [
    "# Assignment: AI Data Architecture Design and Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8727733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from dateutil import parser\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d24025",
   "metadata": {},
   "source": [
    "# upload files from csv data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a663e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    r'D:\\Manish\\LEARNINGS\\BITSOM\\Assigments\\Graded Assigment 3\\customer_raw_data.csv',\n",
    "    r'D:\\Manish\\LEARNINGS\\BITSOM\\Assigments\\Graded Assigment 3\\product_raw_data.csv',\n",
    "    r'D:\\Manish\\LEARNINGS\\BITSOM\\Assigments\\Graded Assigment 3\\order_data.csv',\n",
    "    r'D:\\Manish\\LEARNINGS\\BITSOM\\Assigments\\Graded Assigment 3\\order_item_data1.csv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9423f9",
   "metadata": {},
   "source": [
    "# Read files on pd system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b84971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  customer_id first_name last_name                     email         phone  \\\n",
      "0        C001      Rahul    Sharma    rahul.sharma@gmail.com  9.876543e+09   \n",
      "1        C002      Priya     Patel     priya.patel@yahoo.com -9.988777e+09   \n",
      "2        C003       Amit     Kumar                       NaN  9.765432e+09   \n",
      "3        C004      Sneha     Reddy     sneha.reddy@gmail.com  9.123457e+09   \n",
      "4        C005     Vikram     Singh  vikram.singh@outlook.com  9.988112e+09   \n",
      "\n",
      "        city registration_date  \n",
      "0  Bangalore        15-01-2023  \n",
      "1     Mumbai        20-02-2023  \n",
      "2      Delhi        10-03-2023  \n",
      "3  Hyderabad        15-04-2023  \n",
      "4    Chennai        22-05-2023  \n",
      "  product_id        product_name     category    price  stock_quantity\n",
      "0       P001  Samsung Galaxy S21  Electronics  45999.0           150.0\n",
      "1       P002  Nike Running Shoes      fashion   3499.0            80.0\n",
      "2       P003   Apple MacBook Pro  ELECTRONICS      NaN            45.0\n",
      "3       P004        Levi's Jeans      Fashion   2999.0           120.0\n",
      "4       P005     Sony Headphones  electronics   1999.0           200.0\n",
      "   order_id customer_id  order_date     status  quantity  unit_price\n",
      "0         1        C001  15-01-2024  Completed         1       45999\n",
      "1         2        C002  16-01-2024  Completed         2        2999\n",
      "2         3        C003  15-01-2024  Completed         1       52999\n",
      "3         4         NaN  18-01-2024    Pending         1        3499\n",
      "4         5        C005  20-01-2024  Completed         3         650\n",
      "   order_item_id  order_id product_id  quantity  unit_price  subtotal\n",
      "0            101         1       P001         1       45999     45999\n",
      "1            102         2       P004         2        2999      5998\n",
      "2            103         3       P007         1       52999     52999\n",
      "3            104         4       P002         1        3499      3499\n",
      "4            105         5       P009         3         650      1950\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(files[0])\n",
    "print(df.head())\n",
    "df=pd.read_csv(files[1])\n",
    "print(df.head())\n",
    "df=pd.read_csv(files[2])\n",
    "print(df.head())\n",
    "df=pd.read_csv(files[3])\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80689f6f",
   "metadata": {},
   "source": [
    "# File Cleaning Process \n",
    "# Customer data File 0 / Product data File 1 / Order data File 2 / Order Item File 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dde327e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record count: 26\n",
      "Duplicate records removed: 1\n",
      "Total missing values after cleaning: 0\n",
      "After cleaning:\n",
      "Final record count: 25\n",
      "customer_id          0\n",
      "first_name           0\n",
      "last_name            0\n",
      "email                0\n",
      "phone                0\n",
      "city                 0\n",
      "registration_date    0\n",
      "dtype: int64\n",
      "  customer_id first_name last_name                     email        phone  \\\n",
      "0        C001      Rahul    Sharma    rahul.sharma@gmail.com  98765432100   \n",
      "1        C002      Priya     Patel     priya.patel@yahoo.com  99887765640   \n",
      "2        C003       Amit     Kumar          C003@noemail.com  97654321090   \n",
      "3        C004      Sneha     Reddy     sneha.reddy@gmail.com  91234567890   \n",
      "4        C005     Vikram     Singh  vikram.singh@outlook.com  99881122330   \n",
      "\n",
      "        city registration_date  \n",
      "0  Bangalore        2023-01-15  \n",
      "1     Mumbai        2023-02-20  \n",
      "2      Delhi        2023-10-03  \n",
      "3  Hyderabad        2023-04-15  \n",
      "4    Chennai        2023-05-22  \n"
     ]
    }
   ],
   "source": [
    "# CLEANING PROCESS File 0 - Customer data\n",
    "df=pd.read_csv(files[0])\n",
    "\n",
    "print(\"Initial record count:\", len(df))\n",
    "\n",
    "df.replace({r'^\\s*$': np.nan}, regex=True, inplace=True) \n",
    "\n",
    "df['email'] = df['email'].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "df['email'] = df['email'].fillna(\n",
    "    df['customer_id'].astype(str) + '@noemail.com'\n",
    ")\n",
    "\n",
    "df['phone'] = (\n",
    "    df['phone']\n",
    "    .astype(str)\n",
    "    .str.replace(r'\\D', '', regex=True)\n",
    "    .where(lambda x: x.str.len() >= 10)\n",
    ")\n",
    "\n",
    "\n",
    "df['registration_date'] = df['registration_date'].apply(lambda x: parser.parse(x).date() if pd.notnull(x) else x)\n",
    "\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f'Duplicate records removed: {duplicate_count}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(f'Total missing values after cleaning: {missing_values}')\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Final record count:\", len(df))\n",
    "print(df.isnull().sum())\n",
    "df = df.replace({np.nan: None})\n",
    "print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4de2a71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record count: 20\n",
      "Duplicate records removed: 0\n",
      "Total missing values after cleaning: 4\n",
      "After cleaning:\n",
      "Final record count: 20\n",
      "product_id        0\n",
      "product_name      0\n",
      "category          0\n",
      "price             3\n",
      "stock_quantity    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CLEANING PROCESS  FILE 1\n",
    "df=pd.read_csv(files[1])\n",
    "\n",
    "# 1. intitial records\n",
    "print(\"Initial record count:\", len(df))\n",
    "\n",
    "# 2. Replace empty strings with NaN\n",
    "df.replace({r'^\\s*$': np.nan}, regex=True, inplace=True) \n",
    "df = df.replace({np.nan: None}) \n",
    "# df['email'] = df['email'].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "# df['phone'] = df['phone'].apply(lambda x: re.sub(r'\\D', '', x) if isinstance(x, str) else x)\n",
    "# df['registration_date'] = df['registration_date'].apply(lambda x: parser.parse(x).date() if pd.notnull(x) else x)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f'Duplicate records removed: {duplicate_count}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(f'Total missing values after cleaning: {missing_values}')\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Final record count:\", len(df))\n",
    "print(df.isnull().sum())\n",
    "df = df.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa823660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record count: 41\n",
      "Duplicate records removed: 1\n",
      "Total missing values after cleaning: 3\n",
      "After cleaning:\n",
      "Final record count: 40\n",
      "order_id       0\n",
      "customer_id    3\n",
      "order_date     0\n",
      "status         0\n",
      "quantity       0\n",
      "unit_price     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# CLEANING PROCESS FILE 2\n",
    "df=pd.read_csv(files[2])\n",
    "print(\"Initial record count:\", len(df))\n",
    "df.replace({r'^\\s*$': np.nan}, regex=True, inplace=True)\n",
    "# df['email'] = df['email'].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "# df['phone'] = df['phone'].apply(lambda x: re.sub(r'\\D', '', x) if isinstance(x, str) else x)\n",
    "df['order_date'] = df['order_date'].apply(lambda x: parser.parse(x).date() if pd.notnull(x) else x)\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f'Duplicate records removed: {duplicate_count}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(f'Total missing values after cleaning: {missing_values}')\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Final record count:\", len(df))\n",
    "print(df.isnull().sum())\n",
    "df = df.replace({np.nan: None})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ac10be",
   "metadata": {},
   "source": [
    "# Creation of total amount column in order table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1951c74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id customer_id  order_date     status  total_amount\n",
      "0         1        C001  2024-01-15  Completed         45999\n",
      "1         2        C002  2024-01-16  Completed          5998\n",
      "2         3        C003  2024-01-15  Completed         52999\n",
      "3         5        C005  2024-01-20  Completed          1950\n",
      "4         6        C006  2024-01-22  Completed         12999\n"
     ]
    }
   ],
   "source": [
    "df['subtotal'] = df['quantity'] * df['unit_price']\n",
    "\n",
    "orders_df = (\n",
    "    df\n",
    "    .groupby(['order_id', 'customer_id', 'order_date', 'status'], as_index=False)\n",
    "    .agg(total_amount=('subtotal', 'sum'))\n",
    ")\n",
    "\n",
    "orders_df['order_date'] = pd.to_datetime(\n",
    "    orders_df['order_date'],\n",
    "    errors='coerce',\n",
    "    dayfirst=True\n",
    ").dt.date\n",
    "\n",
    "# Remove bad rows\n",
    "orders_df = orders_df.dropna(subset=['customer_id', 'order_date', 'total_amount'])\n",
    "\n",
    "print(orders_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "111ce879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record count: 41\n",
      "Duplicate records removed: 1\n",
      "Total missing values after cleaning: 2\n",
      "After cleaning:\n",
      "Final record count: 40\n",
      "order_item_id    0\n",
      "order_id         0\n",
      "product_id       2\n",
      "quantity         0\n",
      "unit_price       0\n",
      "subtotal         0\n",
      "dtype: int64\n",
      "   order_item_id  order_id product_id  quantity  unit_price  subtotal\n",
      "0            101         1       P001         1       45999     45999\n",
      "1            102         2       P004         2        2999      5998\n",
      "2            103         3       P007         1       52999     52999\n",
      "3            104         4       P002         1        3499      3499\n",
      "4            105         5       P009         3         650      1950\n"
     ]
    }
   ],
   "source": [
    "# CLEANING PROCESS File 3\n",
    "df=pd.read_csv(files[3])\n",
    "\n",
    "print(\"Initial record count:\", len(df))\n",
    "\n",
    "df.replace({r'^\\s*$': np.nan}, regex=True, inplace=True) \n",
    "\n",
    "# df['email'] = df['email'].apply(lambda x: x.strip().lower() if isinstance(x, str) else x)\n",
    "\n",
    "# df['phone'] = df['phone'].apply(lambda x: re.sub(r'\\D', '', x) if isinstance(x, str) else x)\n",
    "\n",
    "# df['registration_date'] = df['registration_date'].apply(lambda x: parser.parse(x).date() if pd.notnull(x) else x)\n",
    "\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f'Duplicate records removed: {duplicate_count}')\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(f'Total missing values after cleaning: {missing_values}')\n",
    "\n",
    "print(\"After cleaning:\")\n",
    "print(\"Final record count:\", len(df))\n",
    "print(df.isnull().sum())\n",
    "df = df.replace({np.nan: None})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc96d9",
   "metadata": {},
   "source": [
    "# UPLOAD into MYSQL system\n",
    "# Customer data File 0 / Product data File 1 / Order data File 2 / Order Item File 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1004e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data inserted successfully: 25\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector \n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Mannu@510\",\n",
    "    database=\"fleximart\"\n",
    ")  \n",
    "\n",
    "cursor = conn.cursor() # \n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT IGNORE INTO customers\n",
    "(customer_id,first_name, last_name, email, phone, city, registration_date)\n",
    "VALUES (%s,%s, %s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "### IGNORE is added as already product id is fed into mysql product table. \n",
    "# so to avoid double reading put IGNORE. otherwsie not required\n",
    "inserted = 0\n",
    "for _, row in df.iterrows():\n",
    "    cursor.execute(insert_query, \n",
    "    (   row['customer_id'],\n",
    "        row['first_name'],\n",
    "        row['last_name'],\n",
    "        row['email'],\n",
    "        row['phone'],\n",
    "        row['city'],\n",
    "        row['registration_date']\n",
    "    ))\n",
    "    inserted += 1\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "print(\"✅ Data inserted successfully:\", inserted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02557c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data inserted successfully: 25\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Mannu@510\",\n",
    "    database=\"fleximart\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_query = \"\"\" \n",
    "INSERT IGNORE INTO Products  \n",
    "(product_id, product_name, category, price, stock_quantity)\n",
    "VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    cursor.execute(insert_query, (\n",
    "        row['product_id'],\n",
    "        row['product_name'],\n",
    "        row['category'],\n",
    "        row['price'],\n",
    "        row['stock_quantity']\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(\"✅ Data inserted successfully:\", inserted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c4cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Orders inserted: 37\n"
     ]
    }
   ],
   "source": [
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Mannu@510\",\n",
    "    database=\"fleximart\",\n",
    "    autocommit=True\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT IGNORE INTO orders (order_id, customer_id, order_date, total_amount, status)\n",
    "VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "inserted = 0\n",
    "for _, row in orders_df.iterrows():\n",
    "    cursor.execute(insert_query, (\n",
    "        row['order_id'],\n",
    "        row['customer_id'],\n",
    "        row['order_date'],\n",
    "        float(row['total_amount']),\n",
    "        str(row['status'])\n",
    "    ))\n",
    "    inserted += 1\n",
    "\n",
    "print(\"✅ Orders inserted:\", inserted)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd88e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data inserted successfully: 37\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector \n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Mannu@510\",\n",
    "    database=\"fleximart\"\n",
    ")  \n",
    "\n",
    "cursor = conn.cursor() # \n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT IGNORE INTO order_items\n",
    "(order_item_id, order_id, product_id, quantity, unit_price,\n",
    "       subtotal)\n",
    "VALUES (%s,%s, %s, %s, %s, %s)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    cursor.execute(insert_query, \n",
    "    (   row['order_item_id'],\n",
    "        row['order_id'],\n",
    "        row['product_id'],\n",
    "        row['quantity'],\n",
    "        row['unit_price'],\n",
    "        row['subtotal']\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(\"✅ Data inserted successfully:\", inserted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b363fb9",
   "metadata": {},
   "source": [
    "data_quality_report.txt- Generated report showing:\n",
    "\n",
    "Customer Data\n",
    "Number of records processed per file - 26\n",
    "Number of duplicates removed - 1\n",
    "Number of missing values handled - 0\n",
    "Number of records loaded successfully - 25\n",
    "\n",
    "Product Data\n",
    "Number of records processed per file- 20\n",
    "Number of duplicates removed - 0\n",
    "Number of missing values handled - 4\n",
    "Number of records loaded successfully - 25\n",
    "\n",
    "Order Data\n",
    "Number of records processed per file - 41\n",
    "Number of duplicates removed - 1\n",
    "Number of missing values handled - 3\n",
    "Number of records loaded successfully - 37\n",
    "\n",
    "Order Item  Data\n",
    "Number of records processed per file - 41\n",
    "Number of duplicates removed - 1\n",
    "Number of missing values handled - 2\n",
    "Number of records loaded successfully - 37"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
